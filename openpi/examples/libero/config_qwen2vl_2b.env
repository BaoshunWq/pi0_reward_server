# Qwen2-VL-2B-Instruct 评估配置文件
# 使用方法: source config_qwen2vl_2b.env && bash test_qwen2vl_2b.sh

# ==========================================
# 模型配置
# ==========================================

# 后端类型: qwenvl (VLM模式) 或 verl_qwen (LLM模式)
export BACKEND=qwenvl

# Qwen 模式: local (本地推理) 或 api (云端API)
export QWEN_MODE=local

# 模型ID
# Local 模式可选:
#   - Qwen/Qwen2-VL-2B-Instruct (推荐，显存需求小 ~8GB)
#   - Qwen/Qwen2.5-VL-7B-Instruct (显存需求大 ~20GB)
# API 模式可选:
#   - qwen2.5-vl-72b-instruct
export QWEN_MODEL_ID=Qwen/Qwen2-VL-2B-Instruct

# API Key (仅 API 模式需要)
# export DASHSCOPE_API_KEY=your-api-key-here

# ==========================================
# 服务器配置
# ==========================================

# Policy 服务器地址和端口（负载均衡器）
export HOST=0.0.0.0
export PORT=6000

# ==========================================
# 任务配置
# ==========================================

# 任务集名称
# 可选: libero_spatial, libero_object, libero_goal, libero_10, libero_90
export TASK_SUITE=libero_spatial

# 每个任务的试验次数
export NUM_TRIALS=2

# 生成的指令数量
export NUM_INSTRUCTIONS=5

# 从生成的指令中选择 Top-K 个进行评估
export SELECT_TOPK=3

# ==========================================
# 语义相似度配置
# ==========================================

# 语义相似度模型类型
# 可选: clip, deberta
export SEMANTIC_TYPE=clip

# ==========================================
# 输出配置
# ==========================================

# 是否保存视频 (true/false)
# 注意: 保存视频会占用大量磁盘空间和时间
export SAVE_VIDEOS=false

# 是否使用 WandB 记录实验 (true/false)
export USE_WANDB=false

# WandB 配置 (仅当 USE_WANDB=true 时需要)
# export WANDB_PROJECT=qwen2vl_2b_libero_eval
# export WANDB_ENTITY=your-wandb-entity

# ==========================================
# GPU 配置
# ==========================================

# 指定使用的 GPU
# 注意: 这会影响模型加载，但不影响 Policy 服务器（服务器有自己的 GPU 配置）
export CUDA_VISIBLE_DEVICES=0

# ==========================================
# 高级配置
# ==========================================

# 随机种子
export SEED=7

# 失败阈值（成功次数低于此值视为失败指令）
export FAILURE_THRESHOLD=5

# 重新规划步数
export REPLAN_STEPS=5

# 图像调整大小
export RESIZE_SIZE=224

# ==========================================
# 使用示例
# ==========================================

# 1. 加载配置
#    source config_qwen2vl_2b.env

# 2. 运行测试
#    bash test_qwen2vl_2b.sh

# 3. 或者直接运行 Python 脚本
#    python unified_eval.py \
#        --mode vlm \
#        --backend ${BACKEND} \
#        --qwen-mode ${QWEN_MODE} \
#        --qwen-model-id ${QWEN_MODEL_ID} \
#        --host ${HOST} \
#        --port ${PORT} \
#        --task-suite-name ${TASK_SUITE} \
#        --num-trials-per-task ${NUM_TRIALS} \
#        --num-instructions ${NUM_INSTRUCTIONS} \
#        --select-topk ${SELECT_TOPK} \
#        --semantic-type ${SEMANTIC_TYPE}
